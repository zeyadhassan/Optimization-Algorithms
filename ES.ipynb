{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72e9a4ce",
   "metadata": {},
   "source": [
    "# Evolutionary Strategy (ES) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62c08f5",
   "metadata": {},
   "source": [
    "# Define objective functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d35b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def f1(x, y):\n",
    "    return x ** 2.0 + y ** 2.0\n",
    "\n",
    "\n",
    "def f2(x, y):\n",
    "    return np.sin(x) ** 2.0 + np.sin(y) ** 2.0 + 0.005 * (x ** 2.0 + y ** 2.0)\n",
    "\n",
    "\n",
    "def f3(x, y):\n",
    "    return 50.0 * abs(x + y) + x ** 2.0\n",
    "\n",
    "\n",
    "def f4(x, y):\n",
    "    return x ** 2.0 + 50.0 * y ** 2.0\n",
    "\n",
    "\n",
    "def Ackley(x, y):\n",
    "    \"\"\"\n",
    "    A multidimensional function. minimum at [0,0,..0] equals to 0. usually evaluated\n",
    "    on hypercube: [-32.768, 32.768]\n",
    "           x :  Each column of x represents one point\n",
    "           d :  dimension\n",
    "    \"\"\"\n",
    "    X = np.asarray([x, y])\n",
    "    a = 20.0\n",
    "    b = 0.2\n",
    "    c = 2 * np.pi\n",
    "    s = (\n",
    "        -a * np.exp(-b * np.sqrt(1.0 / 2 * np.sum(np.square(X), 0)))\n",
    "        - np.exp(1.0 / 2 * np.sum(np.cos(c * X), 0))\n",
    "        + a\n",
    "        + np.exp(1)\n",
    "    )\n",
    "    return s\n",
    "\n",
    "\n",
    "def Levy(x, y):\n",
    "    wx = (x + 3.0) / 4.0\n",
    "    wy = (y + 3.0) / 4.0\n",
    "\n",
    "    s = np.sin(np.pi * wx) ** 2 + (wy - 1) * (wy - 1) * (\n",
    "        1 + np.sin(2 * np.pi * wy) ** 2\n",
    "    )\n",
    "    s += (wx - 1) * (wx - 1) * (1 + 10 * np.sin(np.pi * wx) ** 2)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc0719",
   "metadata": {},
   "source": [
    "# Plot mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b85c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mesh points\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import get_ipython\n",
    "\n",
    "# for interactive plots\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"widget\")\n",
    "\n",
    "x = np.arange(0, 6, 1)\n",
    "y = np.arange(10, 13, 1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "print(\"Array (shape): content\")\n",
    "print(f\"x {x.shape}: {x} \\ny {y.shape}: {y}\")\n",
    "print(f\"X {X.shape}: \\n{X}\\nY {Y.shape}: \\n{Y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.reshape(-1), Y.reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985a4a7",
   "metadata": {},
   "source": [
    "# Plot an objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b0e30",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "f = Ackley\n",
    "\n",
    "delta = 0.5\n",
    "x = np.arange(-20, 20, delta)\n",
    "y = np.arange(-20, 20, delta)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "# plot\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot_surface(X, Y, Z, cmap=\"coolwarm\")\n",
    "ax2.contour(X, Y, Z, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016be568",
   "metadata": {},
   "source": [
    "# Initializing population of size: $\\mu$\n",
    "- An individual contains more than the decision variables.\n",
    "- Furthermore, it contains standard deviations and rotation angles.\n",
    "- The decision variables are real values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4fe7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_population(Mu, n, lb, ub, sigma_0, n_sigma, alpha_0, n_alpha):\n",
    "    \"\"\"Initializes a population with decision variables and variables defining the mutation. This allows the mutations\n",
    "    to adapt.\n",
    "\n",
    "    Args:\n",
    "        Mu: number of parents\n",
    "        n: number of decision variables\n",
    "        lb: lower limit of search domain\n",
    "        ub: upper limit of search domain\n",
    "        sigma_0: initial standard deviation value\n",
    "        n_sigma: number of standard deviation values\n",
    "        alpha_0: initial rotation angle (between 0 and pi)\n",
    "        n_alpha: number of rotation angles\n",
    " \n",
    "    Returns: \n",
    "        array of tuples: (object variables, standard deviations, rotation angles)\n",
    "    \"\"\"\n",
    "    population = []\n",
    "\n",
    "    # loop over all parent individuals\n",
    "    for i in range(Mu):\n",
    "        # Initialize randomly the vector of design variables.\n",
    "        x = [np.random.uniform(lb, ub) for _ in range(n)]\n",
    "\n",
    "        # Initialize the list of standard deviations.\n",
    "        sigma = [sigma_0 for _ in range(n_sigma)]\n",
    "\n",
    "        # Initialize the list of rotation angles.\n",
    "        alpha = [alpha_0 for _ in range(n_alpha)]\n",
    "\n",
    "        # Concatenate to an individual\n",
    "        individual = (x, sigma, alpha)\n",
    "\n",
    "        population.append(individual)\n",
    "\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f91da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize population\n",
    "pop = initial_population(\n",
    "    Mu=5, n=2, lb=0, ub=10, sigma_0=1, n_sigma=2, alpha_0=0, n_alpha=1\n",
    ")\n",
    "print(\"Population:\")\n",
    "print(*pop, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75136039",
   "metadata": {},
   "source": [
    "# Evaluate cost of each individual\n",
    "- Cost of an individual depends only on the decision variables\n",
    "- We miminize cost in ES (Remember that in GA, we maximized fitness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(population, f):\n",
    "    \"\"\"Computes cost value for each individual in a population\n",
    "    Args:\n",
    "        population: list of individuals\n",
    "        f: objective function \n",
    "    Returns:\n",
    "        list of cost values for each individual    \n",
    "    \"\"\"\n",
    "\n",
    "    cost = []\n",
    "\n",
    "    for individual in population:\n",
    "        x, y = individual[0]  # extract only the decision variables\n",
    "        cost.append(f(x, y))\n",
    "\n",
    "    # Return list of cost values.\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5db8b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Evaluate cost\n",
    "G0 = initial_population(\n",
    "    Mu=5, n=2, lb=0, ub=10, sigma_0=1, n_sigma=2, alpha_0=0, n_alpha=2\n",
    ")\n",
    "fG0 = evaluate(G0, f=f)\n",
    "for i, fi in zip(G0, fG0):\n",
    "    print(f\"Cost of {i} = {fi:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee89bf",
   "metadata": {},
   "source": [
    "# Recombine to generate offsprings ($\\lambda > \\mu$) from a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recombine(population, Lambda, print_all=False):\n",
    "    \"\"\"Recombines individuals in a population to generate offsprings\n",
    "\n",
    "    Args:\n",
    "        population: population of individuals\n",
    "        Lambda: number of offsprings\n",
    "        print_all: Flag to print details\n",
    "    Returns:\n",
    "        list of offsprings\n",
    "    \"\"\"\n",
    "    Mu = len(population)  # population size\n",
    "\n",
    "    # generate n=Lambda offsprings\n",
    "    recombined_population = []\n",
    "    for i in range(Lambda):\n",
    "        # Randomly choose two different parents\n",
    "        # Improvement: Here cost based selection could be used!\n",
    "        # Think roulette wheel with fitness that is ordered opposite to cost\n",
    "        if Mu > 1:\n",
    "            i1, i2 = np.random.choice(Mu, 2, replace=False)\n",
    "        else:\n",
    "            i1, i2 = (0, 0)\n",
    "\n",
    "        individual_1 = population[i1]\n",
    "        individual_2 = population[i2]\n",
    "\n",
    "        # Discrete recombination of object variables (decision variables)\n",
    "        # Each decision variable of offspring comes from one of the two parents.\n",
    "        # Improvement: Instead of discrete recombination, interpolation can be used!\n",
    "        x_1 = individual_1[0]\n",
    "        x_2 = individual_2[0]\n",
    "        x_new = []\n",
    "        assert len(x_1) == len(x_2)\n",
    "        for j in range(len(x_1)):\n",
    "            # For each component of the object variables' vector, choose randomly the parent.\n",
    "            r = np.random.choice([0, 1])\n",
    "            # Take the value from parent 1 or 2.\n",
    "            if r == 0:\n",
    "                x_new.append(x_1[j])\n",
    "            elif r == 1:\n",
    "                x_new.append(x_2[j])\n",
    "\n",
    "        # Intermediate recombination of standard deviations\n",
    "        sigma_1 = np.asarray(individual_1[1])\n",
    "        sigma_2 = np.asarray(individual_2[1])\n",
    "        sigma_new = (sigma_1 + sigma_2) / 2.0\n",
    "\n",
    "        # Intermediate recombination of rotation angles\n",
    "        alpha_1 = np.asarray(individual_1[2])\n",
    "        alpha_2 = np.asarray(individual_2[2])\n",
    "        alpha_new = (alpha_1 + alpha_2) / 2.0\n",
    "\n",
    "        # add new decision variables, sigma and alpha\n",
    "        new_individual = (x_new, sigma_new, alpha_new)\n",
    "        recombined_population.append(new_individual)\n",
    "\n",
    "        if print_all:\n",
    "            p1x, p1y = individual_1[0]\n",
    "            p2x, p2y = individual_2[0]\n",
    "            cx, cy = x_new\n",
    "            print(\n",
    "                f\"Combination of decision variables ({p1x:.2f}, {p1y:.2f}), ({p2x:.2f}, {p2y:.2f}) gives ({cx:.2f}, {cy:.2f})\"\n",
    "            )\n",
    "\n",
    "    return recombined_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e71b45",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# print initial population\n",
    "G0 = initial_population(\n",
    "    Mu=5, n=2, lb=0, ub=10, sigma_0=1, n_sigma=2, alpha_0=0, n_alpha=2\n",
    ")\n",
    "C0 = recombine(G0, Lambda=7, print_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bc245",
   "metadata": {},
   "source": [
    "# Mutate individuals based on standard deviation and correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(population, ax, lb, ub, plotting=False):\n",
    "    \"\"\"Mutates offspring population. Also plots mutation profile if plotting = True\n",
    "\n",
    "    Args:\n",
    "        population: list of individuals\n",
    "        ax: axis for plotting mutation profile\n",
    "        lb: lower bound of search space\n",
    "        ub: upper bound of search space\n",
    "        plotting: flag to activate plotting mutation profile\n",
    "\n",
    "    Returns: list of mutated individuals        \n",
    "    \"\"\"\n",
    "    mutated_population = []\n",
    "\n",
    "    # Number of decision variables\n",
    "    dim = len(population[0][0])\n",
    "\n",
    "    # Default parameters for Evolution Strategy.\n",
    "    # Learning rate when one global standard deviation is given\n",
    "    tau_0 = 1.0 / np.sqrt(dim)\n",
    "\n",
    "    # Learning rates when multiple standard deviations are used\n",
    "    tau = 1.0 / np.sqrt(2 * np.sqrt(dim))\n",
    "    tau_prime = 1.0 / np.sqrt(2 * dim)\n",
    "    beta = 0.0873  # 5 degree\n",
    "\n",
    "    # Loop over all individuals in the population.\n",
    "    for individual in population:\n",
    "        # Get the vector of object variables, standard deviations and rotation angles.\n",
    "        x, sigma, alpha = individual\n",
    "        n_sigma = len(sigma)\n",
    "        n_alpha = len(alpha)\n",
    "\n",
    "        # Generation of a random number from standard normal distribution (mean=0, standard deviation=1.0).\n",
    "        N = np.random.normal(0, 1)\n",
    "\n",
    "        # Choose a self-adaptation strategy\n",
    "        if n_sigma == 1:\n",
    "            # Single step size strategy\n",
    "            sigma = [sigma[0] * np.exp(tau_0 * N)]\n",
    "        else:\n",
    "            # Treat each sigma separately\n",
    "            for i in range(n_sigma):\n",
    "                N_i = np.random.normal(0, 1)\n",
    "                sigma[i] = sigma[i] * np.exp(tau_prime * N + tau * N_i)\n",
    "\n",
    "        # Mutate rotation angles. Not relevant until number of decision variables (n) >= 2.\n",
    "        for i in range(n_alpha):\n",
    "            alpha[i] = alpha[i] + beta * np.random.normal(0, 1)\n",
    "\n",
    "        # Construct covariance matrix based on the mutated standard deviations and rotation angles.\n",
    "        C = np.zeros(shape=(dim, dim))\n",
    "        if n_sigma == 1:\n",
    "            for i in range(dim):\n",
    "                C[i][i] = sigma[0] ** 2.0\n",
    "        elif n_sigma == dim:\n",
    "            for i in range(dim):\n",
    "                C[i][i] = sigma[i] ** 2.0\n",
    "\n",
    "            # Improvement: Implement for higher dimensions\n",
    "            if n_alpha == 1 and dim == 2:\n",
    "                # Construct rotation matrix.\n",
    "                R = np.array(\n",
    "                    [\n",
    "                        [np.cos(alpha[0]), -np.sin(alpha[0])],\n",
    "                        [np.sin(alpha[0]), np.cos(alpha[0])],\n",
    "                    ]\n",
    "                )\n",
    "                # Rotate covariance matrix\n",
    "                C = np.dot(np.dot(R, C), np.linalg.inv(R))\n",
    "            else:\n",
    "                raise (\"Not implemented for multiple alpha and dim != 2\")\n",
    "\n",
    "        # Plot lines of equal probablity density to place an offspring.\n",
    "        if plotting:\n",
    "            plot_eq_prob_density(x, C, ax, level=1, lb=lb, ub=ub)\n",
    "\n",
    "        # Mutate object variables using multivariate normal distribution.\n",
    "        mean = np.zeros(dim)\n",
    "        x = np.array(x) + np.random.multivariate_normal(mean, C)\n",
    "        x = x.tolist()\n",
    "\n",
    "        mutated_population.append((x, sigma, alpha))\n",
    "\n",
    "    return mutated_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f0c30",
   "metadata": {},
   "source": [
    "# Select $\\mu$ best individuals based on cost from $\\lambda$ parents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edcc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(population, cost, Mu):\n",
    "    \"\"\"Selects 'Mu' best individuals from 'Lambda' number of new generation.\n",
    "    Selection stage in brackets: Mu -> (Lambda -> Mu)\n",
    "    Args:\n",
    "        population: list of individuals\n",
    "        cost: cost of population\n",
    "        Mu: number of best individuals selected\n",
    "    Returns: list of best individuals\n",
    "    \"\"\"\n",
    "    new_population = []\n",
    "    # Sort according to the minimal value of the objective function.\n",
    "    min_cost = np.argsort(cost)\n",
    "\n",
    "    # Select Mu best offspring to create new parent population.\n",
    "    # Improvement: make the selection stochastic.\n",
    "    # Lower the cost, higher the probability of selection.\n",
    "    for i in range(Mu):\n",
    "        new_population.append(population[min_cost[i]])\n",
    "\n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafbad5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Example selection\n",
    "pop = [\"a\", \"b\", \"c\", \"d\"]\n",
    "cost = [2, 3, 1, 10]\n",
    "selected = select(pop, cost, Mu=2)\n",
    "print(f\"From population {pop} with cost {cost},\\n{selected} are selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcfa433",
   "metadata": {},
   "source": [
    "# Summary of generation count ($\\mu$ < $\\lambda$)\n",
    "- Recombination: $\\mu$ parents to $\\lambda$ children\n",
    "- Mutation: $\\lambda$ to $\\lambda$ individuals\n",
    "- Selection: $\\lambda$ individuals to $\\mu$ parents for the next iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232c64f0",
   "metadata": {},
   "source": [
    "# Plotting functions needed to demonstrate the ES algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function points corresponding to the positions of parent individuals.\n",
    "def plot_parents(population, ax, color=\"blue\", alpha=1.0, face=True):\n",
    "    for i in range(len(population)):\n",
    "        x, y = population[i][0]\n",
    "        if face:\n",
    "            ax.scatter(x, y, color=color, s=70, alpha=alpha)\n",
    "        else:\n",
    "            ax.scatter(x, y, color=color, s=70, facecolors=\"none\", alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function points corresponding to the positions of offspring individuals.\n",
    "def plot_offspring(population, ax, alpha=1.0, face=True):\n",
    "    plot_parents(population, ax, color=\"red\", alpha=alpha, face=face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b82ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function convergence of the objective (cost) function.\n",
    "def plot_convergence(t, history, ax):\n",
    "    ax.plot(range(0, t + 2), history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returning maximal standard deviation in population.\n",
    "def get_max_sigma(population):\n",
    "    sigma = [max(individual[1]) for individual in population]\n",
    "    return max(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772267fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function lines of equal probability density to place an offspring (just for 2D cases).\n",
    "def plot_eq_prob_density(pos, C, ax, level, lb, ub):\n",
    "    C = np.linalg.inv(C)\n",
    "\n",
    "    delta = 0.1\n",
    "    x = np.arange(lb, ub, delta)\n",
    "    y = np.arange(lb, ub, delta)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    # ellipsoid function centered around each individual\n",
    "    Z = (\n",
    "        C[0][0] * (X - pos[0]) ** 2\n",
    "        + C[1][0] * (X - pos[0]) * (Y - pos[1])\n",
    "        + C[0][1] * (X - pos[0]) * (Y - pos[1])\n",
    "        + C[1][1] * (Y - pos[1]) ** 2\n",
    "    )\n",
    "\n",
    "    ax.contour(X, Y, Z, levels=[level, level + 0.0001], alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989f106",
   "metadata": {},
   "source": [
    "# Minimize an objective (cost) using Evolutionary Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b638d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy as cp\n",
    "\n",
    "\n",
    "def ES(\n",
    "    Mu,\n",
    "    Lambda,\n",
    "    f,\n",
    "    sigma_0=0.5,\n",
    "    n_sigma=1,\n",
    "    alpha_0=0,\n",
    "    n_alpha=0,\n",
    "    selection=\",\",\n",
    "    t_max=20,\n",
    "    lb=-20.0,\n",
    "    ub=20.0,\n",
    "    print_parents=False,\n",
    "):\n",
    "    \"\"\"Evolutionary Strategy algorithm.\n",
    "\n",
    "    Usage:\n",
    "    # Requires fig, ax1, ax2, ax3 defined before calling this function.\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax3 = fig.add_subplot(224)\n",
    "\n",
    "    # In a different Jupyter cell, run ES\n",
    "    ES(...)\n",
    "\n",
    "\n",
    "    Args:\n",
    "        Mu: Parent population size\n",
    "        Lambda: Offspring population size\n",
    "        sigma_0: Initial step size\n",
    "        n_sigma: Number of standard deviations (step sizes)\n",
    "        alpha_0: Initial value of the rotation angle\n",
    "        n_alpha: Number of rotation angles\n",
    "        selection: selection mechanism. ',': (Mu, Lambda); '+': (Mu+Lambda)\n",
    "        t_max: number of iterations\n",
    "        lb: lower limit\n",
    "        ub: upper limit\n",
    "        verbose: flag for some prints\n",
    "    \"\"\"\n",
    "    # Resolution of the plot.\n",
    "    delta = 0.1\n",
    "    x = np.arange(lb, ub, delta)\n",
    "    y = np.arange(lb, ub, delta)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = f(X, Y)\n",
    "\n",
    "    # Dimensionality of the optimization problem.\n",
    "    n = 2\n",
    "\n",
    "    cost_history = []\n",
    "    sigma_history = []\n",
    "\n",
    "    # Initialization of the parent population.\n",
    "    pop = initial_population(Mu, n, -20.0, 20.0, sigma_0, n_sigma, alpha_0, n_alpha)\n",
    "    # Evaluation of the initial parent population.\n",
    "    cost = evaluate(pop, f)\n",
    "\n",
    "    # Tracking of cost values and maximal step sizes.\n",
    "    cost_history.append(min(cost))\n",
    "    sigma_history.append(get_max_sigma(pop))\n",
    "\n",
    "    parents = cp.deepcopy(pop)\n",
    "\n",
    "    # Note that fig, ax1, ax2, ax3 need to be globally defined.\n",
    "\n",
    "    # Main optimization loop.\n",
    "    for t in range(t_max):\n",
    "        # Plotting of figures.\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        ax3.clear()\n",
    "\n",
    "        fig.suptitle(\"Iteration = {0:>3}\".format(t + 1))\n",
    "        ax1.set_title(\"Contour plot of the objective function\")\n",
    "        ax2.set_title(\"Convergence of the objective function\")\n",
    "        ax3.set_title(\"Maximal step size\")\n",
    "\n",
    "        ax1.set_xlim([lb, ub])\n",
    "        ax1.set_ylim([lb, ub])\n",
    "        ax1.grid()\n",
    "        ax1.set_xlabel(\"x\")\n",
    "        ax1.set_ylabel(\"y\", rotation=0)\n",
    "        #             ax1.contour(X, Y, Z, cmap=cm.coolwarm, antialiased=False)  # faster\n",
    "        ax1.contour(X, Y, Z, cmap=\"coolwarm\")\n",
    "\n",
    "        # Recombination.\n",
    "        pop = recombine(pop, Lambda)\n",
    "\n",
    "        # Mutation.\n",
    "        pop = mutate(pop, ax1, lb, ub, plotting=True)\n",
    "        # Plotting of the offspring population.\n",
    "        plot_offspring(pop, ax1)\n",
    "\n",
    "        # Selection.\n",
    "        if selection == \"+\":  # (Mu + Lambda) strategy\n",
    "            # Evaluation of the offspring and parent population.\n",
    "            cost = evaluate(pop + parents, f)\n",
    "            pop = select(pop + parents, cost, Mu)\n",
    "        elif selection == \",\":  # (Mu, Lambda) strategy\n",
    "            # Evaluation of the offspring population.\n",
    "            cost = evaluate(pop, f)\n",
    "            pop = select(pop, cost, Mu)\n",
    "\n",
    "        parents = cp.deepcopy(pop)\n",
    "        if print_parents:\n",
    "            print(parents)\n",
    "        plot_parents(pop, ax1)\n",
    "\n",
    "        # Convergence plot.\n",
    "        cost_history.append(min(cost))\n",
    "        plot_convergence(t, cost_history, ax2)\n",
    "\n",
    "        # Plot evolution of maximal sigma.\n",
    "        sigma_history.append(get_max_sigma(pop))\n",
    "        plot_convergence(t, sigma_history, ax3)\n",
    "\n",
    "        # output to figure\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a622ec00",
   "metadata": {},
   "source": [
    "# Using , selection strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd856c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a03b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization of the process, see above\n",
    "ES(\n",
    "    Mu=5,\n",
    "    Lambda=35,\n",
    "    f=Ackley,\n",
    "    selection=\",\",\n",
    "    sigma_0=1,\n",
    "    n_sigma=2,\n",
    "    alpha_0=0,\n",
    "    n_alpha=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52e802",
   "metadata": {},
   "source": [
    "# Using + selection strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization of the process, see above\n",
    "ES(\n",
    "    Mu=5,\n",
    "    Lambda=35,\n",
    "    f=Ackley,\n",
    "    selection=\"+\",\n",
    "    sigma_0=1,\n",
    "    n_sigma=2,\n",
    "    alpha_0=0,\n",
    "    n_alpha=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77ba5f",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "- Is + better than , strategy for the objective functions? How do we verify?\n",
    "- Minimize Levy function\n",
    "- Implement cost based selection instead of random selection used here. Does it improve convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e654d261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
